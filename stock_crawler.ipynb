{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import re\n",
    "from urllib.parse import urljoin,urlencode\n",
    "import multiprocessing\n",
    "import time\n",
    "import json\n",
    "from os import makedirs\n",
    "from os.path import exists\n",
    "import pandas as pd\n",
    "from lxml import etree\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver import ActionChains\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver import ChromeOptions\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO,format='%(asctime)s - %(levelname)s: %(message)s')\n",
    "# 基础网址和爬取页码数量设定\n",
    "BASE_URL='https://www.9fzt.com/marketCenter/aStockMarket.html?tab=0'\n",
    "TOT_PAGEs=10\n",
    "def get_browser():\n",
    "    option=ChromeOptions()\n",
    "    option.add_experimental_option('excludeSwitches',['enable-automation'])\n",
    "    option.add_experimental_option('useAutomationExtension',False)\n",
    "    # 设置不显式地显示浏览器\n",
    "    option.add_argument('--headless')\n",
    "    browser=webdriver.Chrome(options=option)\n",
    "    browser.execute_cdp_cmd(\"Page.addScriptToEvaluateOnNewDocument\",\n",
    "                            {'source': 'Object.defineProperty(navigator,\"webdriver\",{get:()=>undefind})'})\n",
    "    browser.implicitly_wait(10)\n",
    "    return browser\n",
    "\n",
    "\n",
    "# %%\n",
    "# 解析 html 中的 urls\n",
    "def parse_page(page_html,protol_type='https:'):\n",
    "    pattern=re.compile('序号(.*)',re.S)\n",
    "    stock_urls=re.findall(pattern,page_html)\n",
    "    pattern=re.compile('<a href=\"(.*?)\".*? class=\"bluelink ff_din-medium fw-500\" target=\"_blank\" rel=\"noopener\">',re.S)\n",
    "    stock_urls=re.findall(pattern,str(stock_urls))\n",
    "    stock_urls=[urljoin(protol_type,url) for url in stock_urls]\n",
    "    return stock_urls\n",
    "\n",
    "\n",
    "# %%\n",
    "# 爬取股票数据列表 urls\n",
    "def scrape_stock_list(browser,page_num):\n",
    "    browser.get(BASE_URL)\n",
    "    urls=[]\n",
    "    WebDriverWait(browser,20,0.5).until(lambda browser:len(\n",
    "        browser.find_element(By.XPATH,'//*[@id=\"__next\"]/div/div[3]/div[2]/ul[20]/li[13]/span').text)>0)\n",
    "    for page in range(page_num):\n",
    "        if(page >= 4):\n",
    "            # continue\n",
    "            urls+=(parse_page(browser.page_source))\n",
    "        time.sleep(0.2)\n",
    "        ac=ActionChains(browser)\n",
    "        # 鼠标移动到下一页按钮上\n",
    "        ac.move_to_element(browser.find_element(By.NAME, 'whj_nextPage')).perform()\n",
    "        # 点击确定跳转至下一页\n",
    "        ac.click(browser.find_element(By.NAME, 'whj_nextPage')).perform()\n",
    "        time.sleep(0.2)\n",
    "        WebDriverWait(browser,10,0.5).until(lambda browser: len(\n",
    "            browser.find_element(By.XPATH,'//*[@id=\"__next\"]/div/div[3]/div[2]/ul[20]/li[13]/span').text)>0)\n",
    "    print(urls)\n",
    "    return urls\n",
    "\n",
    "\n",
    "browser = webdriver.Chrome()\n",
    "urls=scrape_stock_list(browser,TOT_PAGEs)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# %%\n",
    "# 爬取公司各个页面 html ，以list形式返回\n",
    "def scrape_company_list(browser,urls):\n",
    "    companys=[]\n",
    "    cnt = 0\n",
    "    for url in urls:\n",
    "        logging.info('scraping %s...',url)\n",
    "        browser.get(url)\n",
    "\n",
    "        logging.info('scraping 公司资料...')\n",
    "        browser.find_element(By.LINK_TEXT, '公司资料').click()\n",
    "        browser.switch_to.window(browser.window_handles[1])\n",
    "        WebDriverWait(browser,15,2).until(lambda browser: len(\n",
    "            browser.find_element(By.XPATH,'//*[@id=\"xxqk\"]/div[2]/div/div/section/div/ul/li[4]/div[2]/section/div/div').text)>0)\n",
    "        data=browser.page_source\n",
    "        browser.close()\n",
    "        browser.switch_to.window(browser.window_handles[0])\n",
    "\n",
    "        logging.info('scraping 股东研究...')\n",
    "        browser.find_element(By.LINK_TEXT, '股东研究').click()\n",
    "        browser.switch_to.window(browser.window_handles[1])\n",
    "        WebDriverWait(browser,10,2).until(lambda browser: len(browser.find_element(By.XPATH, '//*[@id=\"sdgd\"]/div[2]/div/div/section/div[2]/div/div/div/div/div/table').text)>0)\n",
    "        shareholder=browser.page_source\n",
    "        browser.close()\n",
    "        browser.switch_to.window(browser.window_handles[0])\n",
    "\n",
    "\n",
    "        logging.info('scraping 涉及概念...')\n",
    "        browser.find_element(By.LINK_TEXT, '最新动态').click()\n",
    "        browser.switch_to.window(browser.window_handles[1])\n",
    "        WebDriverWait(browser,10,2).until(lambda browser: len(browser.find_element(By.XPATH, '//*[@id=\"gsgy\"]/div[2]/div/div/section/div/ul/li[2]/div[2]/div/span').text)>0)\n",
    "        concept=browser.page_source\n",
    "        browser.close()\n",
    "        browser.switch_to.window(browser.window_handles[0])\n",
    "\n",
    "\n",
    "        logging.info('scraping 公司公告...')\n",
    "        browser.find_element(By.LINK_TEXT, '更多').click()\n",
    "        browser.switch_to.window(browser.window_handles[1])\n",
    "        WebDriverWait(browser,10,0.5).until(lambda browser: len(\n",
    "            browser.find_element(By.XPATH,'//*[@id=\"app\"]/div/section/div[1]/section/div[1]/div/div/div[2]/ul/li[12]/div').text)>0)\n",
    "        # 模拟移动点击跳转\n",
    "        time.sleep(0.3)\n",
    "        ac = ActionChains(browser)\n",
    "        ac.move_to_element(browser.find_element(By.XPATH,'//*[@id=\"app\"]/div/section/div[1]/section/div[1]/div/div/div[2]/ul/li[12]/div')).perform()\n",
    "        ac.click(browser.find_element(By.XPATH,'//*[@id=\"app\"]/div/section/div[1]/section/div[1]/div/div/div[2]/ul/li[12]/div')).perform()\n",
    "        time.sleep(0.3)\n",
    "        # 等待公告加载完成\n",
    "        WebDriverWait(browser, 10, 2).until(lambda browser: len(\n",
    "            browser.find_element(By.XPATH,\n",
    "                                 '//*[@id=\"MediaGszx0\"]').text)>0)\n",
    "        news=browser.page_source\n",
    "        browser.close()\n",
    "        browser.switch_to.window(browser.window_handles[0])\n",
    "\n",
    "        companys.append([data, shareholder, concept, news])\n",
    "        print(cnt)\n",
    "\n",
    "        cnt += 1\n",
    "\n",
    "        # if(cnt == 20):\n",
    "        #     break\n",
    "    return companys\n",
    "\n",
    "\n",
    "companys=scrape_company_list(browser,urls)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# %%\n",
    "# 使用xpath匹配\n",
    "stock_code_name_xpath='//*[@id=\"app\"]/div/section/div[1]/section/div[1]/div/div/div[1]/h3/i/text()'\n",
    "company_name_xpath='//*[@id=\"xxqk\"]/div[2]/div/div/section/div/ul/li[1]/div[2]/div/span/text()'\n",
    "company_time_xpath='//*[@id=\"xxqk\"]/div[2]/div/div/section/div/ul/li[5]/div[2]/div/span/text()'\n",
    "company_business_xpath='//*[@id=\"xxqk\"]/div[2]/div/div/section/div/ul/li[23]/div[2]/div/span/text()'\n",
    "company_representative_xpath='//*[@id=\"xxqk\"]/div[2]/div/div/section/div/ul/li[9]/div[2]/div/span/text()'\n",
    "company_manager_xpath='//*[@id=\"xxqk\"]/div[2]/div/div/section/div/ul/li[10]/div[2]/div/span/text()'\n",
    "company_hangye_xpath='//*[@id=\"xxqk\"]/div[2]/div/div/section/div/ul/li[8]/div[2]/div/span/text()'\n",
    "company_secretary_xpath='//*[@id=\"xxqk\"]/div[2]/div/div/section/div/ul/li[11]/div[2]/div/span/text()'\n",
    "company_phone_xpath='//*[@id=\"xxqk\"]/div[2]/div/div/section/div/ul/li[14]/div[2]/div/span/text()'\n",
    "company_place_pattern='//*[@id=\"xxqk\"]/div[2]/div/div/section/div/ul/li[18]/div[2]/div/span/text()'\n",
    "\n",
    "# 使用re匹配\n",
    "city_pattern=re.compile('(.*?省)?(.*?市)?',re.S)\n",
    "company_id_pattern=re.compile('(</html>.*)', re.S)\n",
    "\n",
    "# 对已经得到的 html 进行解析——股票基本数据\n",
    "def parse_company_data(html):\n",
    "    html=etree.HTML(html)\n",
    "    code_name = html.xpath(stock_code_name_xpath)[0].split(' ')\n",
    "    stock_code = code_name[0]\n",
    "    stock_name = code_name[1]\n",
    "    company_place=html.xpath(company_place_pattern)[0]\n",
    "    province='--'\n",
    "    city='--'\n",
    "    if re.search(city_pattern,company_place).group(1):\n",
    "        province=re.search(city_pattern,company_place).group(1)\n",
    "    if re.search(city_pattern,company_place).group(2):\n",
    "        city=re.search(city_pattern,company_place).group(2)\n",
    "    company_name=html.xpath(company_name_xpath)[0]\n",
    "    company_time=html.xpath(company_time_xpath)[0]\n",
    "    company_hangye=html.xpath(company_hangye_xpath)[0]\n",
    "    company_business=html.xpath(company_business_xpath)[0]\n",
    "    company_representative=html.xpath(company_representative_xpath)[0]\n",
    "    company_manager=html.xpath(company_manager_xpath)[0]\n",
    "    company_secretary=html.xpath(company_secretary_xpath)[0]\n",
    "    company_phone=html.xpath(company_phone_xpath)[0]\n",
    "    return [stock_code,stock_name,company_name,province,city,company_time,company_hangye,company_business,company_representative,\n",
    "            company_manager,company_secretary,company_phone]\n",
    "\n",
    "def get_table_company_data(data):\n",
    "    table=pd.DataFrame(columns=['stock_code','stock_name','company_name','province','city',\n",
    "                                'company_time','行业','company_business','company_representative',\n",
    "                                'company_manager','company_secretary','company_phone'])\n",
    "    for item in data:\n",
    "        table.loc[len(table)]=parse_company_data(item)\n",
    "    return table\n",
    "\n",
    "data=[company[0] for company in companys]\n",
    "company_data_table=get_table_company_data(data)\n",
    "company_data_table.to_csv('company_data_table.csv',index=False,encoding='gbk')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 对已经得到的 html 进行解析——股东基本信息\n",
    "def parse_sharehold(html, id):\n",
    "    company_id = company_id_pattern.search(html).group(1)[7:]\n",
    "    html = etree.HTML(html)\n",
    "    subfix0 = '\"]/text()'\n",
    "    subfix1 = ']/span/text()'\n",
    "    name0 = '//*[@id=\"SHNameTopTenSH'\n",
    "    nature0 = '//*[@id=\"SHNatureTopTenSH'\n",
    "    type0 = '//*[@id=\"ShareTypeTopTenSH'\n",
    "    prefix0 = '//*[@id=\"sdgd\"]/div[2]/div/div/section/div[2]/div/div/div/div/div/table/tbody/tr['\n",
    "    number1 = ']/td[5]/span/text()'\n",
    "    rate1 = ']/td[6]/span/text()'\n",
    "    change1 = ']/td[7]/span/text()'\n",
    "    name = html.xpath(name0 + str(id) + subfix0)[0]\n",
    "    nature = html.xpath(nature0 + str(id) + subfix0)[0]\n",
    "    type = html.xpath(type0 + str(id) + subfix0)[0]\n",
    "    number = html.xpath(prefix0 + str(id + 1) + number1)[0]\n",
    "    rate = html.xpath(prefix0 + str(id + 1) + rate1)[0]\n",
    "    change = html.xpath(prefix0 + str(id + 1) + change1)[0]\n",
    "    return [company_id, name,  nature, type, number, rate, change]\n",
    "\n",
    "\n",
    "def get_table_sharehold_data(data):\n",
    "    table = pd.DataFrame(columns=['stock_code', '股东名称', '股东性质', '股份类型', '持股数(股)', '占总股本比例', '增减(股)'])\n",
    "    # , '股东性质'\n",
    "    for item in data:\n",
    "        for id in range(10):\n",
    "            table.loc[len(table)] = parse_sharehold(item, id)\n",
    "\n",
    "    return table\n",
    "\n",
    "\n",
    "sharehold = [company[1] for company in companys]\n",
    "for i in range(len(sharehold)):\n",
    "    sharehold[i] = sharehold[i] + company_data_table.loc[i][0]\n",
    "share_data_table = get_table_sharehold_data(sharehold)\n",
    "\n",
    "# print(company_data_table)\n",
    "share_data_table.to_csv('sharehold_data_table.csv', index=False, encoding='gbk')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 对已经得到的 html 进行解析——基金基本信息\n",
    "def parse_fund(html, id):\n",
    "    company_id = company_id_pattern.search(html).group(1)[7:]\n",
    "    html = etree.HTML(html)\n",
    "    fund_id_xpath0 = '//*[@id=\"jjcg\"]/div[2]/div/div/section/div[2]/div/div/div/div/div/table/tbody/tr['\n",
    "    fund_id_xpath1 = ']/td[2]/text()'\n",
    "    fund_name_xpath0 = '//*[@id=\"FundNameFundHold'\n",
    "    fund_name_xpath1 = '\"]/text()'\n",
    "    fund_number_xpath0 = '//*[@id=\"jjcg\"]/div[2]/div/div/section/div[2]/div/div/div/div/div/table/tbody/tr['\n",
    "    fund_number_xpath1 = ']/td[4]/span/text()'\n",
    "    fund_rate_xpath0 = '//*[@id=\"jjcg\"]/div[2]/div/div/section/div[2]/div/div/div/div/div/table/tbody/tr['\n",
    "    fund_rate_xpath1 = ']/td[6]/span/text()'\n",
    "    if len(html.xpath(fund_number_xpath0 + str(id + 1) + fund_number_xpath1)) == 0:\n",
    "        return None\n",
    "    fund_id = html.xpath(fund_id_xpath0 + str(id + 1) + fund_id_xpath1)[0]\n",
    "    fund_name = html.xpath(fund_name_xpath0 + str(id) + fund_name_xpath1)[0]\n",
    "    fund_number = html.xpath(fund_number_xpath0 + str(id + 1) + fund_number_xpath1)[0]\n",
    "    fund_rate = html.xpath(fund_rate_xpath0 + str(id + 1) + fund_rate_xpath1)[0]\n",
    "    return [company_id, fund_id, fund_name, fund_number, fund_rate]\n",
    "def get_table_fund_data(data):\n",
    "    table = pd.DataFrame(\n",
    "        columns=['stock_code', '基金代码', '基金名称', '持股数(股)', '占总股本比例'])\n",
    "    for item in data:\n",
    "        for id in range(10):\n",
    "            tmp = parse_fund(item, id)\n",
    "            if tmp != None:\n",
    "                table.loc[len(table)] = parse_fund(item, id)\n",
    "    return table\n",
    "fund_data_table = get_table_fund_data(sharehold)\n",
    "fund_data_table.to_csv('fund_data_table.csv', index=False,encoding='gbk')\n",
    "# print(fund_data_table)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 对已经得到的 html 进行解析——股票概念基本信息\n",
    "def get_table_cept_data(data):\n",
    "    table = pd.DataFrame(columns=['stock_code', '概念'])\n",
    "\n",
    "    for item in data:\n",
    "        company_id = company_id_pattern.search(item).group(1)[7:]\n",
    "        html = etree.HTML(item)\n",
    "        target = html.xpath('//*[@id=\"gsgy\"]/div[2]/div/div/section/div/ul/li[2]/div[2]/div/span/text()')[0]\n",
    "        op = target.split(',')\n",
    "        for x in op:\n",
    "            table.loc[len(table)] = [company_id, x]\n",
    "    return table\n",
    "concept = [company[2] for company in companys]\n",
    "for i in range(len(concept)):\n",
    "    concept[i] = concept[i] + company_data_table.loc[i][0]\n",
    "fund_data_table = get_table_cept_data(concept)\n",
    "fund_data_table.to_csv('concept_data_table.csv', index=False,encoding='gbk')\n",
    "print(fund_data_table)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 对已经得到的 html 进行解析——公告基本信息\n",
    "def parse_news(html, id):\n",
    "    company_id = company_id_pattern.search(html).group(1)[7:]\n",
    "    html = etree.HTML(html)\n",
    "    news_date_xpath0 = '//*[@id=\"gsggDetail\"]/div[2]/section/div/div/section/div/div/div/div/div/div/table/tbody/tr['\n",
    "    news_date_xpath1 = ']/td[1]/text()'\n",
    "    news_name_xpath0 = '//*[@id=\"ggTitleGszxDetail'\n",
    "    news_name_xpath1 = '\"]/text()'\n",
    "    if len(html.xpath(news_name_xpath0 + str(id) + news_name_xpath1)) == 0:\n",
    "        return None\n",
    "    news_date = html.xpath(news_date_xpath0 + str(id+1) + news_date_xpath1)[0]\n",
    "    news_name = html.xpath(news_name_xpath0 + str(id) + news_name_xpath1)[0]\n",
    "    print(company_id)\n",
    "    return [company_id, news_date, news_name]\n",
    "\n",
    "def get_table_news_data(data):\n",
    "    table = pd.DataFrame(columns=['stock_code', '时间', '公告'])\n",
    "\n",
    "    for item in data:\n",
    "        for id in range(10):\n",
    "            tmp = parse_news(item, id)\n",
    "            if tmp != None:\n",
    "                table.loc[len(table)] = parse_news(item, id)\n",
    "\n",
    "    return table\n",
    "\n",
    "news = [company[3] for company in companys]\n",
    "for i in range(len(news)):\n",
    "    news[i] = news[i] + company_data_table.loc[i][0]\n",
    "news_data_table = get_table_news_data(news)\n",
    "news_data_table.to_csv('news_data_table.csv', index=False,encoding='gbk')\n",
    "print(news_data_table)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
